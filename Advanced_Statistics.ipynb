{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "earned-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-latino",
   "metadata": {},
   "source": [
    "# Point and Interval Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-summer",
   "metadata": {},
   "source": [
    "## Point Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fantastic-webmaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point estimate for the population mean: 28.07\n"
     ]
    }
   ],
   "source": [
    "x = np.array([100, 104, 105, 107, 110, 115])\n",
    "x = np.array([28.7, 27.9, 29.2, 26.5])\n",
    "print(f'Point estimate for the population mean: {x.mean():0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-plain",
   "metadata": {},
   "source": [
    "## Interval Estimate or Confidence Interval (CI)\n",
    "> From sample data one can calculate the interval within which the population mean is predicted to fall.\n",
    "> Confidence intervals are always estimated for population parameters and in general are derived from the mean & standard deviation of sample data.  \n",
    "\n",
    "> t-distribution confidence interval:   \n",
    "    $$\\bar{X} \\pm t_{n-1} \\frac{s}{\\sqrt n}$$\n",
    "    $t_{n-1}$ is the critical value from t-distribution for ***x% confidence (alpha risk), two tail (alpha/2) with n-1 degrees of freedom***\n",
    "    \n",
    "> z-normal-distribution confidence interval:\n",
    "    $$\\bar{X} \\pm Z \\frac{\\sigma}{\\sqrt n}$$\n",
    "    $Z$ is the critical value from normal distribution for ***x% confidence (alpha risk), two tail (alpha/2)***\n",
    "    \n",
    "> $\\bar{X}$ is the sample mean  \n",
    "> $s$ is the sample standard deviation  \n",
    "> $\\sigma$ is the population standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "concerned-construction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical value (t-dist) for 95% Confidence Interval: [-3.18  3.18]\n",
      "95% Confidence Interval for population mean: 26.45 <= μ <= 29.70\n",
      "Critical value (norm dist) for 95% Confidence Interval: [-1.96  1.96]\n",
      "95% Confidence Interval for population mean: 26.11 <= μ <= 30.04\n"
     ]
    }
   ],
   "source": [
    "# for small samples, t-distribution is used to calculate critical value\n",
    "t_score = stats.t.interval(0.95, df=x.size-1)\n",
    "t_score = np.round(t_score, decimals=2)\n",
    "print(f'Critical value (t-dist) for 95% Confidence Interval: {t_score}')\n",
    "lower_limit = x.mean() + t_score[0] * x.std()/np.sqrt(x.size)\n",
    "higher_limit = x.mean() + t_score[1] * x.std()/np.sqrt(x.size)\n",
    "print(\"95% Confidence Interval for population mean:\", end=' ')\n",
    "print(f'{lower_limit:0.2f}' + ' <= \\u03BC <= ' + f'{higher_limit:0.2f}')\n",
    "\n",
    "# if population standard deviation is known, critical values Z-score can be used\n",
    "# for example if population std dev = 5\n",
    "sd = 2\n",
    "z_score = stats.norm.interval(0.95)\n",
    "z_score = np.round(z_score, decimals=2)\n",
    "print(f'Critical value (norm dist) for 95% Confidence Interval: {z_score}')\n",
    "print(\"95% Confidence Interval for population mean:\", end=' ')\n",
    "lower_limit = x.mean() + z_score[0] * sd/np.sqrt(x.size)\n",
    "higher_limit = x.mean() + z_score[1] * sd/np.sqrt(x.size)\n",
    "\n",
    "print(f'{lower_limit:0.2f}' + ' <= \\u03BC <= ' + f'{higher_limit:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-payday",
   "metadata": {},
   "source": [
    "## MTBF Point Estimation (Non-Censored Data)\n",
    "> When units are tested to failure, either repairable or non-repairable(MTTF), the estimate of the MTBF($\\theta$)is simply the ratio of total test time divided by the number of failures during the test  \n",
    "\n",
    "> $$ MTBF (\\theta) = \\frac {T}{r} $$\n",
    "    T = total time for all units (failed & unfailed)  \n",
    "    r = total number of failures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "wanted-vampire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTBF: 135.38, \n",
      "Failure_Rate: 0.0074\n"
     ]
    }
   ],
   "source": [
    "# total test time on 'several' units\n",
    "t = 1760\n",
    "# failures = 13 out of 'several' units\n",
    "r = 13\n",
    "mtbf = t/r\n",
    "failure_rate = 1/mtbf\n",
    "print(f'MTBF: {mtbf:0.2f}, \\nFailure_Rate: {failure_rate:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-freedom",
   "metadata": {},
   "source": [
    "## MTBF Point Estimation (Censored Data)\n",
    "> Tests are censored(stopped) at either a **pre-planned, predetermined number of hours/cyles, called Type I Censoring** or a **pre-planned, predetermined number of failures, called Type II Censoring**\n",
    "> Type I censoring allows for scheduling when the test will be completed\n",
    "> Type II censoring allows for planning the maximum number of units that will be required for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-parker",
   "metadata": {},
   "source": [
    "### Type I Censoring\n",
    "> MTBF Point Estimate:  \n",
    "> $$MTBF (\\theta) = n \\frac Tr$$ \n",
    "    n = number of items originally placed on test  \n",
    "    T = total test time cycles  \n",
    "    r = number of failures during the test  \n",
    "    \n",
    "> Procees:  \n",
    "A total of n items are placed on test at t=0. The test is set to run a predetermined number of hours/cycles. As individual items fail, they are replaced at the time of failure & run to the prescribed time or cycles still remaining. At predetermined time/cylce the test is terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "distinguished-blame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Time Between Failure Type I Censoring: 600.00\n"
     ]
    }
   ],
   "source": [
    "# 10 items are placed on tests for 240 hours(a cumulative test time of 2400 hours).\n",
    "# As units failed they were replaced with new units. During the test, 4 failures occured\n",
    "# Estimate MTBF\n",
    "n = 10\n",
    "r = 4\n",
    "T = 240\n",
    "mtbf = n*T/r\n",
    "print(f'Mean Time Between Failure Type I Censoring: {mtbf:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-royalty",
   "metadata": {},
   "source": [
    "### Type II Censoring\n",
    "> MTBF Point Estimate:  \n",
    "> $$MTBF, \\theta = \\frac{\\sum_{i=1}^r {y_i} + {(n-r)y_r}}r$$  \n",
    "$y_i$ is the time of failure of the ith item  \n",
    "$y_r$ is the time to failure of the unit terminating the test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "amateur-copying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Time Between Failure Type II Censoring: 1525.00\n"
     ]
    }
   ],
   "source": [
    "# 10 units on test. The test terminated when second failure occurs. \n",
    "# failure 1 at 260 hours, failure 2 at 310 hours. Calculate MTBF, it is point estimate of MTBF\n",
    "\n",
    "n = 10 # total units on test\n",
    "r = 2 # number of failures\n",
    "sum_y = 260 + 310 # sum of failure times\n",
    "y_r = 310 # time when test was terminated after failure 2. \n",
    "mtbf = (sum_y + (n-r)*y_r)/r\n",
    "print(f'Mean Time Between Failure Type II Censoring: {mtbf:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-siemens",
   "metadata": {},
   "source": [
    "# Confidence Intervals\n",
    "- This come into picture when measurement is not point, that is not point estimation.  \n",
    "- In real life situation tests are repeated on samples(sample 1, sample 2, sample 3...each sample containing 'n' number of items under test). In this situation each sample will give different mean & standard deviation. So confidence interval comes into picture to estimate population parameters based on samples. Sometimes we know or guess one of the population parameter like standard deviation & use it with sample mean to calculate confidence interval for population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-arrow",
   "metadata": {},
   "source": [
    "## Confidence Interval for the Mean, Continuous Data-Large Samples\n",
    "> A confidence interval is a two-tail event & requires critical values based on an alpha/2 risk in each tail\n",
    "### Normal Distribution\n",
    "$$\\bar{X} \\pm Z_\\frac{\\alpha}{2} \\frac{\\sigma}{\\sqrt n}$$\n",
    "> from population mean determine confidence interval for population mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "insured-shareware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Distribution value for 95% Confidence Interval: [-1.96  1.96]\n",
      "95% Confidence Interval for population mean: 16.824 <= μ <= 19.176\n"
     ]
    }
   ],
   "source": [
    "(size, mean, std, CI) = (100, 18, 6, 0.95)\n",
    "# calculate critical value (z-score) from Normal distribution for given confidence interval\n",
    "z_score = stats.norm.interval(0.95)\n",
    "z_score = np.round(z_score, decimals=2)\n",
    "print(f'Normal Distribution value for 95% Confidence Interval: {z_score}')\n",
    "print(\"95% Confidence Interval for population mean:\", end=' ')\n",
    "lower_limit = mean + z_score[0] * std/np.sqrt(size)\n",
    "higher_limit = mean + z_score[1] * std/np.sqrt(size)\n",
    "\n",
    "print(str(lower_limit) + ' <= \\u03BC <= ' + str(higher_limit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-pencil",
   "metadata": {},
   "source": [
    "## Confidence Interval for the Mean, Continuous Data-Small Samples < 30\n",
    "### T-Distribution\n",
    "$$\\bar{X} \\pm t_\\frac{\\alpha}{2} \\frac{s}{\\sqrt n}$$\n",
    "> from sample mean determine confidence interval for population mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "occupied-mouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-distribution value for 95% Confidence Interval: [-2.06  2.06]\n",
      "95% Confidence Interval for population mean: 15.528 <= μ <= 20.472\n"
     ]
    }
   ],
   "source": [
    "(size, mean, std, CI) = (25, 18, 6, 0.95)\n",
    "# calculate critical value from T-distribition for given confidence interval\n",
    "t_score = stats.t.interval(0.95, df=size-1)\n",
    "t_score = np.round(t_score, decimals=2)\n",
    "print(f't-distribution value for 95% Confidence Interval: {t_score}')\n",
    "lower_limit = mean + t_score[0] * std/np.sqrt(size)\n",
    "higher_limit = mean + t_score[1] * std/np.sqrt(size)\n",
    "print(\"95% Confidence Interval for population mean:\", end=' ')\n",
    "print(str(lower_limit) + ' <= \\u03BC <= ' + str(higher_limit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-yemen",
   "metadata": {},
   "source": [
    "## Confidence Intervals for Variation\n",
    "### Chi-Square Distribution\n",
    "$$\\frac{(n-1)s^2}{\\chi^2_{\\frac{\\alpha}{2}, {n-1}}} \\le \\sigma^2 \\le \\frac{(n-1)s^2}{\\chi^2_{{1-\\frac{\\alpha}{2}},  {n-1}}} $$\n",
    "> from sample variance determine confidence interval for population variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "congressional-seeker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Distribution value for 95% Confidence Interval: [13.85 36.42]\n",
      "90% Confidence Interval for population variance: 23.72 <= σ2 <= 62.38\n"
     ]
    }
   ],
   "source": [
    "size, sample_variance = (25, 36)\n",
    "# calculate critical value from Chi-Square distibution for given confidence interval\n",
    "chi_score = stats.chi2.interval(0.90, df=size-1)\n",
    "chi_score = np.round(chi_score, decimals=2)\n",
    "print(f'Chi-Square Distribution value for 95% Confidence Interval: {chi_score}')\n",
    "print(\"90% Confidence Interval for population variance:\", end=' ')\n",
    "lower_limit = (size-1)*sample_variance/chi_score[1]\n",
    "higher_limit = (size-1)*sample_variance/chi_score[0]\n",
    "print(f'{lower_limit:0.2f}' + ' <= ' + '\\u03C32' + ' <= ' + f'{higher_limit:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-labor",
   "metadata": {},
   "source": [
    "## Confidence Intervals for Proportion\n",
    "$$p\\pm Z_\\frac{\\alpha}{2}\\sqrt\\frac{p(1-p)}{n}$$\n",
    "> $p$ is the population proportion estimate  \n",
    "> For large samples sizes, with n(p) & n(1-p) >= 4 or 5 the normal distribution is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "characteristic-consultation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Distribution value for 95% Confidence Interval: [-1.64  1.64]\n",
      "90% Confidence Interval for the Proportion: 0.049 <= p <= 0.111\n"
     ]
    }
   ],
   "source": [
    "# If 16 defectives were found in a sample size of 200 units calculate the 90% confidence interval for the proportion\n",
    "# p = 16/200 = 8/100 = 0.08\n",
    "p = 0.08\n",
    "n = 200\n",
    "z_score = stats.norm.interval(0.90)\n",
    "z_score = np.round(z_score, decimals=2)\n",
    "print(f'Normal Distribution value for 95% Confidence Interval: {z_score}')\n",
    "lower_limit = p + z_score[0] * np.sqrt(p * (1-p)/n)\n",
    "higher_limit = p + z_score[1] * np.sqrt(p * (1-p)/n)\n",
    "print(\"90% Confidence Interval for the Proportion:\", end=' ')\n",
    "print(f'{lower_limit:0.3f}' + ' <= ' + 'p' + ' <= ' + f'{higher_limit:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-quilt",
   "metadata": {},
   "source": [
    "## MTBF Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-agriculture",
   "metadata": {},
   "source": [
    "### Type I Censoring\n",
    "- one sided:\n",
    "$$\\frac{2T}{\\chi^2_{\\alpha, \\, 2r+2}} \\le \\theta$$\n",
    "- two sided:\n",
    "$$\\frac{2T}{\\chi^2_{\\frac{\\alpha}{2}, \\, 2r+2}} \\le \\theta \\le \\frac{2T}{\\chi^2_{1-\\frac{\\alpha}{2}, \\, 2r}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "magnetic-clarity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One sided confidence lower limit: 44.90 hours <= theta at 90.0% confidence\n",
      "Two sided confidence limit:38.69 hours <= theta <= 366.89 hours at 90.0% confidence\n"
     ]
    }
   ],
   "source": [
    "# Test run for 300 hours (Type I censoring). 3 failures occured. Calculate one sided lower & two sided confidence\n",
    "# interval for MTBF at 90% confidence (alpha = 0.10)\n",
    "\n",
    "T = 300\n",
    "r = 3\n",
    "c = 0.90\n",
    "alpha = 1-c\n",
    "one_side_critical_value = stats.chi2.ppf(1-alpha, df=2*r+2)\n",
    "print(f'One sided confidence lower limit: {2*T/one_side_critical_value:0.2f} hours <= theta at {c*100}% confidence')\n",
    "\n",
    "two_side_critical_value_1 = stats.chi2.ppf(1-alpha/2, df=2*r+2)\n",
    "two_side_critical_value_2 = stats.chi2.ppf(1-(1-alpha/2), df=2*r)\n",
    "\n",
    "print(f'Two sided confidence limit:{2*T/two_side_critical_value_1:0.2f} hours <= theta <= {2*T/two_side_critical_value_2:0.2f} hours at {c*100}% confidence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-instrument",
   "metadata": {},
   "source": [
    "### Type II Censoring\n",
    "- one sided:\n",
    "$$\\frac{2T}{\\chi^2_{\\alpha, \\, 2r}} \\le \\theta$$\n",
    "- two sided:\n",
    "$$\\frac{2T}{\\chi^2_{\\frac{\\alpha}{2}, \\, 2r}} \\le \\theta \\le \\frac{2T}{\\chi^2_{1-\\frac{\\alpha}{2}, \\, 2r}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "random-beginning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One sided confidence lower limit: 784.12 hours <= theta at 90.0% confidence\n",
      "Two sided confidence limit:642.94 hours <= theta <= 8582.81 hours at 90.0% confidence\n"
     ]
    }
   ],
   "source": [
    "# Refer to point estimate example of Type II censoring, 10 units on test, two failed\n",
    "# 10 units on test. The test terminated when second failure occurs. \n",
    "# failure 1 at 260 hours, failure 2 at 310 hours. Calculate confidence interval of MTBF.\n",
    "# we know point estimate for MTBF is 1525 hours.\n",
    "\n",
    "# Calculate one-sided lower confidence limit & two-sided confidence interval at 90% confidence\n",
    "# Confidence interval 90% corresponds to alpha = 1-C = 0.10\n",
    "\n",
    "# total test time\n",
    "T = 260 + 310 + 8 * 310 # 3050 hours\n",
    "r = 2\n",
    "c = 0.90\n",
    "alpha = 1-c\n",
    "\n",
    "# for lower limit use ppf, it takes confidence level = 1-alpha\n",
    "chi2_alpha_2r = stats.chi2.ppf(1-alpha, df=2*r)\n",
    "print(f'One sided confidence lower limit: {2*T/chi2_alpha_2r:0.2f} hours <= theta at {c*100}% confidence')\n",
    "\n",
    "# lower & upper limit\n",
    "chi2_alpha_2_2r = stats.chi2.ppf(1-alpha/2, df=2*r)\n",
    "chi2_1_alpha_2_2r = stats.chi2.ppf(1-(1-alpha/2), df=2*r)\n",
    "\n",
    "# or use interval function instead of above two ppf calls, remember df should be same\n",
    "stats.chi2.interval(1-alpha, df=2*r)\n",
    "\n",
    "print(f'Two sided confidence limit:{2*T/chi2_alpha_2_2r:0.2f} hours <= theta <= {2*T/chi2_1_alpha_2_2r:0.2f} hours at {c*100}% confidence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-monte",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "> Inference tests  \n",
    "> on-sided, right, higher region of distribution:  \n",
    "    - if alternate hyothesis is greater than existing, critical_value will be, for example at 95% confidence interval: stats.norm.ppf(0.95)\n",
    "    \n",
    "> one-sided, left, lower region in distribution:  \n",
    "    - if alternate hypothesis is less than existing, critical_value will be for example at 95% confidence interval: stats.norm.ppf(0.05)  \n",
    "    \n",
    "> two-sided:  \n",
    "    - when alternate hypothesis is not equal to existing, critical value will be for example at 95% confidence interval: stats.norm.ppf(0.025) & stats.norm.ppf(0.975)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-valley",
   "metadata": {},
   "source": [
    "### Z-test\n",
    "> Test Statistic: $$Z = \\frac{\\bar X - \\mu}{\\frac{\\sigma}{\\sqrt n}}$$\n",
    "### t-test\n",
    "> Test Statistic: $$t = \\frac{\\bar X - \\mu}{\\frac{S}{\\sqrt n}}$$\n",
    "### 2 Mean Equal Variance t-test\n",
    "> Test Statistic: \n",
    "### 2 Mean Unequal Variance t-Test\n",
    "> Test Statistic:\n",
    "### Paired t-test\n",
    "> Test Statistic: $$ stats.ttest\\_rel() $$\n",
    "### Chi-Squared test with $\\sigma$ square known\n",
    "> Test Statistic: $$\\chi^2 = \\frac{(n-1)S^2}{\\sigma^2}$$\n",
    "### Chi-Squared test\n",
    "> Test Statistic: $$\\chi^2 = \\sum\\frac{(O-E)^2}{E}$$\n",
    "### F-test\n",
    "> Test Statistic: $$F = \\frac{S_1^2}{S_2^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "complex-testament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null hypothesis cannot be rejected\n"
     ]
    }
   ],
   "source": [
    "# Z-test\n",
    "# for example production may be anything like strings, ropes, \n",
    "pm, pd = 5.00, 0.12 #production of a material mean & standard deviaton\n",
    "s = np.array([5.10, 4.90, 4.92, 4.87, 5.09, 4.89, 4.95, 4.88]) # sample from the production\n",
    "sm = s.mean()\n",
    "# Null hypothesis: H0: new_mean>=5.00, H1: new_mean<5.00, there is lower side shift in production.\n",
    "test_statistic = (sm-pm)/(pd/np.sqrt(s.size))\n",
    "c = 0.90\n",
    "alpha = 0.05\n",
    "critical_value = stats.norm.ppf(0.05)\n",
    "if test_statistic < critical_value:\n",
    "    print('Reject the null hypothesis')\n",
    "else:\n",
    "    print('Null hypothesis cannot be rejected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "christian-handling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "-2.063898561628021 2.0638985616280205\n",
      "Reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "# t-test\n",
    "pm = 880 # process average\n",
    "sm, sd = 900, 20 # sample from process\n",
    "n = 25 # for 25 days sample\n",
    "# Hypothesis testing: H0: new_mean=old_mean, H1: new_mean not equal to old_mean\n",
    "# at 95% confidence check the above hypothesis\n",
    "test_statistic = (sm-pm)/(sd/np.sqrt(n))\n",
    "# Two sided 95% confidence limit, lower = 2.5% higher = 97.5, in between 95%\n",
    "# alpha = 1-0.95, in two sided remove alpha/2 on both side, lower side alpha/2, higher 1-alpha/2\n",
    "critical_value_1 = stats.t.ppf(0.025, df=n-1)\n",
    "critical_value_2 = stats.t.ppf(0.975, df=n-1)\n",
    "print(test_statistic)\n",
    "print(critical_value_1, critical_value_2)\n",
    "if (test_statistic < critical_value_1) or (test_statistic > critical_value_1):\n",
    "    print('Reject the null hypothesis')\n",
    "else:\n",
    "    print('Null hypothesis cannot be rejected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "monthly-ballet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.146804162276531"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.f.ppf(0.95, dfn=9-1, dfd=7-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-conversation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-bronze",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
